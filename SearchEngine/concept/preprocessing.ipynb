{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rodrimen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# pip install googletrans==3.1.0a0\n",
    "from googletrans import Translator\n",
    "# lemmatisation\n",
    "# pip install -U pip setuptools wheel\n",
    "# pip install -U spacy\n",
    "# python -m spacy download es_core_news_sm\n",
    "import spacy\n",
    "# stemming\n",
    "# pip install nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "# import nltk\n",
    "\n",
    "# pip install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "# siguiente paso convertir de caracter a numerico (ex. cinco -> 5)\n",
    "# text_to_num.py\n",
    "import text_to_num\n",
    "import timeit\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "# Download NLTK resources\n",
    "download('stopwords')\n",
    "SPANISH_STOPWORDS = stopwords.words('spanish')\n",
    "\n",
    "# Load spaCy model\n",
    "NLP = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Load additional stopwords\n",
    "with open('spanish_stopwords.txt', 'r') as file:\n",
    "    ADDITIONAL_STOPWORDS = file.read().splitlines()\n",
    "STOPWORDS = SPANISH_STOPWORDS + ADDITIONAL_STOPWORDS\n",
    "\n",
    "# Load car makes and models\n",
    "with open('car_makes.txt', 'r') as file:\n",
    "    car_makes = file.read().splitlines()\n",
    "with open('car_models.txt', 'r') as file:\n",
    "    car_models = file.read().splitlines()\n",
    "CAR_MODEL_MAKES = car_makes + car_models\n",
    "\n",
    "# Create spellchecker instance\n",
    "SPANISH_SPELL_CHECKER = SpellChecker(language='es')\n",
    "\n",
    "# Regex compilations for additional performance\n",
    "EMAIL_PATTERN = re.compile(r'\\S*@\\S*\\s?')\n",
    "MENTION_PATTERN = re.compile(r'@\\S*\\s?')\n",
    "URL_PATTERN = re.compile(r'http\\S+|www.\\S+')\n",
    "# symbols_punctuations_pattern = re.compile(r'\\?|\\\\|\\!|\\\"|\\#|\\$|\\%|\\&|\\'|\\[|\\^|\\||\\,|\\¿|\\¡|\\_|\\=|\\>|\\[|\\^|\\`|\\{\n",
    "# |\\}|\\~|\\[|\\]|\\*|\\+|\\@|\\/|\\-|\\:|\\?|\\¡|\\¿||\\.|\\\\|\\“|\\”|\\(|\\)|\\;|\\’|\\;|\\`|\\´|\\-|\\·|\\<|\\º|\\ª')\n",
    "SYMBOL_PATTERN = re.compile(r'[^\\w\\sñ]')\n",
    "SPECIAL_CASE_1 = re.compile(r'\\nd')\n",
    "SPECIAL_CASE_2 = re.compile(r'\\n')\n",
    "HASTAG_PATTERN = re.compile(r'\\B(\\#[a-zA-Z]+\\b)(?!;)')\n",
    "WORD_LENGTH_PATTERN = re.compile(r'\\b\\w{1,2}\\b')\n",
    "A_ACCENT_PATTERN = re.compile(r'[áàäâ]')\n",
    "E_ACCENT_PATTERN = re.compile(r'[éèëê]')\n",
    "I_ACCENT_PATTERN = re.compile(r'[íìïî]')\n",
    "O_ACCENT_PATTERN = re.compile(r'[óòöô]')\n",
    "U_ACCENT_PATTERN = re.compile(r'[úùüû]')\n",
    "ALPHA_NUMERIC_PATTERN = re.compile(r'[^a-zA-Z\\d|\\s|ñ]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def transform_prompt(prompt):\n",
    "    prompt = strip_formatting(prompt)\n",
    "    # prompt = translate_prompt(prompt)\n",
    "    prompt = correct_spelling(prompt)\n",
    "    prompt = lemmatize_prompt(prompt)\n",
    "    prompt = remove_stopwords(prompt)\n",
    "    prompt = convert_to_numeric(prompt)\n",
    "    prompt = strip_formatting(prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def strip_formatting(prompt):\n",
    "    prompt = prompt.lower()\n",
    "    replace_to_blank = [EMAIL_PATTERN, MENTION_PATTERN, URL_PATTERN, SYMBOL_PATTERN, SPECIAL_CASE_1, SPECIAL_CASE_2,\n",
    "                        HASTAG_PATTERN, WORD_LENGTH_PATTERN, ALPHA_NUMERIC_PATTERN]\n",
    "    for pattern in replace_to_blank:\n",
    "        prompt = pattern.sub('', prompt)\n",
    "\n",
    "    replace_to_word = [A_ACCENT_PATTERN, E_ACCENT_PATTERN, I_ACCENT_PATTERN, O_ACCENT_PATTERN, U_ACCENT_PATTERN]\n",
    "    word_to_replace = ['a', 'e', 'i', 'o', 'u']\n",
    "    for pattern in replace_to_word:\n",
    "        prompt = pattern.sub(word_to_replace[replace_to_word.index(pattern)], prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def translate_prompt(prompt):\n",
    "    translator = Translator()\n",
    "    prompt = translator.translate(prompt, dest='es').text\n",
    "    return prompt.lower()\n",
    "\n",
    "\n",
    "def stem_prompt(prompt):\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    return stemmer.stem(prompt)\n",
    "\n",
    "\n",
    "def lemmatize_prompt(prompt):\n",
    "    nlp_prompt = NLP(prompt)\n",
    "    # open cars makes and models to excluse them from the lemmatization\n",
    "    prompt = ' '.join([word.lemma_ if word.text not in CAR_MODEL_MAKES else word.text for word in nlp_prompt])\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def remove_stopwords(prompt):\n",
    "    words = re.findall(r'\\w+', prompt, flags=re.UNICODE)\n",
    "    important_words = (word for word in words if word not in STOPWORDS)\n",
    "    prompt = ' '.join(important_words)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def correct_spelling(prompt):\n",
    "    list_of_words = prompt.split()\n",
    "    corrections = {word: SPANISH_SPELL_CHECKER.correction(word) for word in list_of_words if word not in CAR_MODEL_MAKES}\n",
    "    prompt = ' '.join([corrections.get(word, word) for word in list_of_words])\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def convert_to_numeric(prompt):\n",
    "    return text_to_num.text2num(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.00012199999764561653\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "for x in range(1000):\n",
    "    transform_prompt('hola como estas?')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}